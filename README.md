# About
My name is Park Jae Hyun. I major in Electronic and Electrical Engineering at [POSTECH](https://www.postech.ac.kr/). I earned Master degree at Radio Technology Lab of [Seoul National University](https://www.snu.ac.kr/index.html). Now I'm Ph.D student at Signal Processing & AI Lab of [Seoul National University](https://www.snu.ac.kr/index.html).
Recently, I'm working on 3D Object Detection Tasks exploiting the radar-camera sensor fusion techniques. And I'm highly motivated to create technologically fancy outputs.

This repository is the collection of various research papers that I'm dealing with, which is inspired by [Denny britz](https://github.com/dennybritz/deeplearning-papernotes), [Daniel Takeshi](https://github.com/DanielTakeshi/Paper_Notes) and [Patric Langechuan Liu](https://patrick-llgc.github.io/Learning-Deep-Learning/). The number of asteroid indicates a degree of achievement of the papaer understanding.
For example, the understanding score is based on the checklists
| Main Ideas | Contribution | Methodology | Training Details | Experiments |
| :-----: | :----------: | :----------: | :----------: | :----------: |
<br>

# Paper Lists
### Advanced Deep Learning SNU-2023
- https://incongruous-prepared-cb5.notion.site/579ca645fe7b492985866de6ea75b797
### Vision Language Model SNU-2025
- https://docs.google.com/spreadsheets/d/1J96dnrE8J6-Ll1Ht8R68z-1UYdgBumgdaAJB6sHB9aI/edit?gid=0#gid=0
### Computer Vision in the Wild
- https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings
### AD + Gaussian Splatting
- https://docs.google.com/spreadsheets/d/1Xt4NLJIjILTEXQOiBxQNN1izEGF-rvZt/edit?usp=sharing&ouid=104341429099946347621&rtpof=true&sd=true

# 2025-09
- [OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection
in Autonomous Driving](https://arxiv.org/pdf/2506.23565) <kbd>ICCV 2025</kbd>
- [GaussRender: Learning 3D Occupancy with Gaussian Rendering](https://arxiv.org/pdf/2502.05040) <kbd>ICCV 2025</kbd>
- [GS-Occ3D: Scaling Vision-only Occupancy Reconstruction
with Gaussian Splatting](https://arxiv.org/pdf/2507.19451) <kbd>ICCV 2025</kbd>

- [3D Gaussian Splatting as
Markov Chain Monte Carlo](https://openreview.net/pdf?id=AFMFmkxQuK) <kbd>NIPS 2024 Spotlight</kbd>

** Radial Basis Function **
- [3D-HGS: 3D Half-Gaussian Splatting](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_3D-HGS_3D_Half-Gaussian_Splatting_CVPR_2025_paper.pdf) <kbd>CVPR 2025</kbd>
- [GES : Generalized Exponential Splatting for Efficient Radiance Field Rendering](https://openreview.net/pdf?id=AFMFmkxQuK) <kbd>CVPR 2024</kbd>

# 2025-07
- [InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions](https://arxiv.org/pdf/2211.05778) <kdb>CVPR 2023 Highlight</kbd>


# 2025-06
- [OccFusion: Multi-Sensor Fusion Framework for 3D Semantic Occupancy Prediction](https://arxiv.org/pdf/2403.01644)
- OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction
- SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving
- Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction <kbd>CVPR 2023</kbd>
- VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion
- MonoScene: Monocular 3D Semantic Scene Completion <kbd>CVPR 2022</kbd>
- [FlashOcc: Fast and Memory-Efficient Occupancy Prediction via Channel-to-Height Plugin](https://arxiv.org/abs/2311.12058)
- [A Survey on 3D Gaussian Splatting](https://arxiv.org/pdf/2401.03890)
- [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934) <kbd>ECCV 2020 oral</kbd>
- [VISION TRANSFORMERS NEED REGISTERS](https://arxiv.org/pdf/2309.16588) <kbd>ICLR 2024</kbd>
- [DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception](https://arxiv.org/pdf/2505.04410) <kbd>CVPR 2025</kbd>

# 2025-05
- [RLIP: Relational Language-Image Pre-training for Human-Object Interaction Detection](https://arxiv.org/pdf/2209.01814) <kbd>NeurIPS 2022 Spotlight</kbd> _(HOI Detection)_
- [Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection](https://arxiv.org/pdf/2303.05499) <kbd>ECCV 2024</kbd>
- [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) _(Contrastive Learning)_
- [Speculative Decoding with Big Little Decoder](https://arxiv.org/pdf/2302.07863) _(LLM Infrastructure)_ <kbd>NeurIPS 2023</kbd>
- [Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve](https://arxiv.org/pdf/2403.02310) _(LLM Infrastructure)_
- [Interpretable Image Classification with Adaptive Prototype-based Vision Transformers](https://arxiv.org/pdf/2410.20722) <kbd>NeurIPS 2024</kbd>
- [Inherently Interpretable Tree Ensemble Learning](https://arxiv.org/pdf/2410.19098)
- [Neural Basis Models for Interpretability](https://arxiv.org/pdf/2205.14120) _(Generaelized Additive Models)_
- [ANOVA-NODE: AN IDENTIFIABLE NEURAL NETWORK FOR THE FUNCTIONAL ANOVA MODEL FOR BETTER INTERPRETABILITY](https://openreview.net/pdf?id=Xy1Lf7uR9H)
- [Extracting Training Data from Large Language Models](https://arxiv.org/pdf/2012.07805) _(LLM Data)_
- [Extracting Training Data from Diffusion Models](https://arxiv.org/pdf/2301.13188) _(LLM Data)_

# 2025-04
- [Unifying Feature-Based Explanations with Functional ANOVA and Cooperative Game Theory](https://arxiv.org/pdf/2412.17152)
- [Purifying Interaction Effects with the Functional ANOVA: An Efficient Algorithm for Recovering Identifiable Additive Models](https://proceedings.mlr.press/v108/lengerich20a/lengerich20a.pdf) <kbd>ICML 2020</kbd>
- [A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning](https://arxiv.org/pdf/1012.2599) _(Deep Learning Theory)_
- [Learning to summarize from human feedback](https://arxiv.org/abs/2009.01325) <kbd>NeurIPS 2020</kbd> _(VLM RLHF)_
- [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343) <kbd>ICCV'23 Oral</kbd> _(VLM SigLIP)_
- [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020) _(VLM CLIP)_
- [CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models](https://arxiv.org/pdf/2411.18613) _(VLM)_
- [Random Search for Hyper-Parameter Optimization](https://jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) _(Deep Learning Theory)_
- [Unveiling the Generalization Power of Fine-Tuned Large Language Models](https://arxiv.org/abs/2403.09162) _(LLM)_ <kbd>NAACL 2024</kbd>
- [A Joint Extrinsic Calibration Tool for Radar, Camera and Lidar](https://ieeexplore.ieee.org/document/9380784/) _(Sensor Calibration)_
- [Explaining How Transformers Use Context to Build Predictions](https://arxiv.org/abs/2305.12535) _(Attention Decomposition)_
- [Measuring the Mixing of Contextual Information in the Transformer](https://arxiv.org/abs/2203.04212) _(Attention Decomposition)_
- [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) _(Contrastive Learning)_

# 2025-03
- [Gaussian Process Neural Additive Models](https://arxiv.org/pdf/2402.12518) _(XAI)_ <kbd>AAAI 2024</kbd>
- [NODE-GAM : NEURAL GENERALIZED ADDITIVE MODEL FOR INTERPRETABLE DEEP LEARNING](https://openreview.net/pdf?id=g8NJR6fCCl8) _(XAI)_ <kbd>ICLR 2022</kbd>
- [Neural Additive Models:Interpretable Machine Learning with Neural Nets](https://arxiv.org/pdf/2004.13912) _(XAI)_ <kbd>NIPS 2021</kbd>
- [Exploring the Unseen: A Survey of Multi-Sensor Fusion and the Role of Explainable AI (XAI) in Autonomous Vehicles](https://www.mdpi.com/1424-8220/25/3/856) _(XAI)_
- [Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI Benchmarks](https://arxiv.org/pdf/2401.06654) _(XAI Benchmarks)_
- [Feature Perturbation Augmentation for Reliable Evaluation of Importance Estimators in Neural Networks](https://arxiv.org/pdf/2303.01538)
- [Synthesizing the preferred inputs for neurons in neural networks via deep generator networks](https://arxiv.org/pdf/1605.09304) _(XAI)_ <kbd>NIPS 2016</kbd>
- [Explainable Artificial Intelligence (XAI) 2.0: A manifesto of open challenges and interdisciplinary research directions](https://www.sciencedirect.com/science/article/pii/S1566253524000794) _(XAI_Comprehensive_Review_Paper)_
- [Benign Overfitting in Linear Regression](https://arxiv.org/pdf/1906.11300) _(Deep Learning Theory)_
The definition that "if a model performs well on the training set but poorly on the test set, it is overfitting" can be an oversimplified interpretation !
- [Segment Anything](https://arxiv.org/pdf/2304.02643) _(Semantic Segmentation)_
- [ON LARGE-BATCH TRAINING FOR DEEP LEARNING: GENERALIZATION GAP AND SHARP MINIMA](https://arxiv.org/pdf/1609.04836) _(Deep Learning Theory)_ <kbd>ICLR 2017</kbd>
- [A Closer Look at Memorization in Deep Networks](https://arxiv.org/pdf/1706.05394) _(Deep Learning Theory)_
- [Fantastic Generalization Measures and Where to Find Them](https://arxiv.org/pdf/1912.02178) _(Deep Learning Theory)_ <kbd>ICLR 2020</kbd>
- [Understanding Deep Learning (Still) Requires Rethinking Generalization](https://dl.acm.org/doi/pdf/10.1145/3446776) _(Deep Learning Theory)_
- [V-STRONG: Visual Self-Supervised Traversability Learning for Off-road Navigation](https://arxiv.org/pdf/2312.16016) _(Traversability)_ <kbd>ICRA 2024</kbd>
- [Follow the Footprints: Self-supervised Traversability Estimation for Off-road Vehicle Navigation based on Geometric and Visual Cues](https://arxiv.org/pdf/2402.15363) _(Traversability)_ <kbd>ICRA 2024</kbd>
- [Gaussian Splatting SLAM](https://openaccess.thecvf.com/content/CVPR2024/papers/Matsuki_Gaussian_Splatting_SLAM_CVPR_2024_paper.pdf) _(Gaussian Splatting x SLAM)_ <kbd>CVPR 2024</kbd>
- [Locomotion Policy Guided Traversability Learning using Volumetric Representations of Complex Environments](https://arxiv.org/pdf/2203.15854) _(Traversability)_
- [Traversability Analysis for Autonomous Driving in Complex Environment: A LiDAR-based Terrain Modeling Approach](https://arxiv.org/pdf/2307.02060) _(Traversability)_
- [RadarDistill: Boosting Radar-based Object Detection Performance via Knowledge Distillation from LiDAR Features](https://arxiv.org/abs/2403.05061) _(C-R fusion)_
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961) _(Mixture of Experts)_
- [Scaling Vision with Sparse Mixture of Experts](https://arxiv.org/pdf/2106.05974) __(Mixture of Experts)_

# 2025-02
- [Mask2Map: Vectorized HD Map Construction Using Bird’s Eye View Segmentation Masks](https://arxiv.org/pdf/2407.13517)
- [3D Dual-Fusion: Dual-Domain Dual-Query Camera-LiDAR Fusion for 3D Object Detection](https://arxiv.org/pdf/2211.13529) _(Camera-Lidar Fusion)_
- [CRT-Fusion: Camera, Radar, Temporal Fusion Using Motion Information for 3D Object Detection](https://arxiv.org/pdf/2411.03013) _(Camera-Radar Fusion)_
- [RCM-Fusion: Radar-Camera Multi-Level Fusion for 3D Object Detection](https://arxiv.org/pdf/2307.10249) _(Camera-Radar Fusion)_  
- [Outrageously Large Neural Networks : The Sparsely-Gated Mixture-of-Experts Layer](https://arxiv.org/pdf/1701.06538) _(Mixture of Experts)_ <kbd>ICLR 2017</kbd> 
- [MEGABLOCKS: EFFICIENT SPARSE TRAINING WITH MIXTURE-OF-EXPERTS](https://arxiv.org/pdf/2211.15841) _(Mixture of Experts)_

# 2024-12
- [ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/abs/2101.06840)
- [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/abs/1910.02054)
- [ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](https://arxiv.org/abs/2104.07857)

# 2024-11 [Paper Writing Season]
- [CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_Feature_Decomposition_for_Multi-Modality_Image_Fusion_CVPR_2023_paper.html) <kbd>CVPR 2023</kbd>
- [Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework](https://openreview.net/forum?id=J1gBijopla) <kbd>NIPS 2023</kbd>
- [Sphere Generative Adversarial Network Based on Geometric Moment Matching](https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Sphere_Generative_Adversarial_Network_Based_on_Geometric_Moment_Matching_CVPR_2019_paper.pdf) <kbd>CVPR 2019 Oral</kbd> (GAN) 
- [Transformer Interpretability Beyond Attention Visualization](https://arxiv.org/pdf/2012.09838) (XAI)
- [Understanding Image Captioning Models beyond Visualizing Attention](http://interpretable-ml.org/icml2020workshop/pdf/25.pdf) (XAI)
- [Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation](https://aclanthology.org/2021.acl-long.91.pdf) (XAI)

# 2024-10 
- [BEVMap: Map-Aware BEV Modeling for 3D Perception](https://openaccess.thecvf.com/content/WACV2024/papers/Chang_BEVMap_Map-Aware_BEV_Modeling_for_3D_Perception_WACV_2024_paper.pdf) <kbd>CVPR 2024</kbd> (BEV Perception)
- [Attention Branch Network: Learning of Attention Mechanism for Visual Explanation](https://arxiv.org/pdf/1812.10025) <kbd>CVPR 2019</kbd> (XAI - GradCAM)
- [Explainable AI in Scene Understanding for Autonomous Vehicles in Unstructured Traffic Environments on Indian Roads Using the Inception U-Net Model with Grad-CAM Visualization](https://www.mdpi.com/1424-8220/22/24/9677) (XAI - AV)
- [Explainable Artificial Intelligence for Autonomous Driving: A Comprehensive Overview and Field Guide for Future Research Directions](https://arxiv.org/pdf/2112.11561) (XAI - AV Review)

# 2024-09
- [XAI for Transformers: Better Explanations through Conservative Propagation](https://proceedings.mlr.press/v162/ali22a/ali22a.pdf) <kbd>ICML 2022</kbd> (XAI - LRP)
- [Ground Truth Evaluation of Neural Network Explanations with CLEVR-XAI](https://arxiv.org/pdf/2003.07258)
- [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/pdf/1312.6034)
- [Quantifying Attention Flow in Transformers](https://arxiv.org/pdf/2005.00928) (XAI - Attention Rollout)
- [Layer-Wise Relevance Propagation with Conservation Property for ResNet](https://arxiv.org/abs/2407.09115) <kbd>ECCV 2024</kbd> (XAI - LRP)
- [AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for Transformers](https://arxiv.org/pdf/2402.05602) <kbd>NIPS 2024</kbd> (XAI - LRP)
- [Layer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers](https://arxiv.org/pdf/1604.00825) (XAI - LRP)
- [LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise Relevance Propagation](https://arxiv.org/pdf/2401.11243) (XAI - LRP)
- [Vision Transformer with Deformable Attention](https://arxiv.org/pdf/2201.00520) <kbd>CVPR 2022</kbd>
- [VISUALIZING DEEP NEURAL NETWORK DECISIONS:PREDICTION DIFFERENCE ANALYSIS](https://arxiv.org/pdf/1702.04595) <kbd>ICLR 2017</kbd>
- [Explaining NonLinear Classification Decisions with Deep Taylor Decomposition](https://arxiv.org/pdf/1512.02479)
- [Axiomatic Attribution for Deep Networks](https://arxiv.org/pdf/1512.02479)

# 2024-08
- [Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf) <kbd>ICCV 2023</kbd>
- [AdaMixer: A Fast-Converging Query-Based Object Detector](https://arxiv.org/pdf/2203.16507) <kbd>CVPR Oral 2022</kbd>
- [Center-based 3D Object Detection and Tracking](https://arxiv.org/pdf/2006.11275) <kbd>CVPR 2021</kbd>
- [Dynamic DETR: End-to-End Object Detection with Dynamic Attention](https://openaccess.thecvf.com/content/ICCV2021/papers/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.pdf) <kbd>ICCV 2021</kbd>
- [PointPillars: Fast Encoders for Object Detection from Point Clouds](https://openaccess.thecvf.com/content_CVPR_2019/papers/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.pdf) <kbd>CVPR 2020</kbd>
- [BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo](https://arxiv.org/abs/2209.10248) <kbd>AAAI 2023 </kbd>


# 2024-07
- [ON THE RELATIONSHIP BETWEEN SELF-ATTENTION AND CONVOLUTIONAL LAYERS](https://arxiv.org/pdf/1911.03584) <kbd>ICLR 2020</kbd>
- [BEVFormer v2: Adapting Modern Image Backbones to Bird’s-Eye-View Recognition via Perspective Supervision](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BEVFormer_v2_Adapting_Modern_Image_Backbones_to_Birds-Eye-View_Recognition_via_CVPR_2023_paper.pdf) <kbd>CVPR 2023</kbd>
- [PointPillars: Fast Encoders for Object Detection from Point Clouds](https://openaccess.thecvf.com/content_CVPR_2019/papers/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.pdf) <kbd>CVPR 2019</kbd>
- [DETRs with Collaborative Hybrid Assignments Training](https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf) <kbd>ICCV 2023</kbd>
- [Fast Convergence of DETR with Spatially Modulated Co-Attention](https://arxiv.org/pdf/2101.07448) <kbd>ICCV 2021</kbd>
- [Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity](https://arxiv.org/abs/2111.14330) <kbd>ICLR 2022</kbd>
- [Dynamic Filter Networks](https://arxiv.org/abs/1605.09673) <kbd>NIPS 2016</kbd>
- [Dynamic Sparse R-CNN](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.pdf) <kbd>CVPR 2022</kbd>
- [Object Detection with Transformers: A Review](https://arxiv.org/pdf/2306.04670)
- [DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR](https://arxiv.org/abs/2201.12329) <kbd>ICLR 2022</kbd>
- [DN-DETR: Accelerate DETR Training by Introducing Query DeNoising](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.pdf) <kbd>CVPR 2022</kbd>
- [Sparse R-CNN: End-to-End Object Detection with Learnable Proposals](https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Sparse_R-CNN_End-to-End_Object_Detection_With_Learnable_Proposals_CVPR_2021_paper.pdf) <kbd>CVPR 2021</kbd>
- [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection](https://arxiv.org/abs/2203.03605) <kbd>ICLR 2023</kbd>
- [Conditional DETR for Fast Training Convergence](https://arxiv.org/pdf/2108.06152) <kbd>ICCV 2021</kbd>
- [PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection](https://arxiv.org/pdf/2205.07403) <kbd>ECCV 2022</kbd>
- [Anchor DETR: Query Design for Transformer-Based Object Detection](https://arxiv.org/pdf/2109.07107)
- [BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection](https://arxiv.org/abs/2203.17054)
- [PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.pdf) <kbd>ICCV 2023</kbd>
- [PETR: Position Embedding Transformation for Multi-View 3D Object Detection](https://sunkyoo.github.io/opencv4cvml/) <kbd>ECCV 2022</kbd>
- [DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.pdf) <kbd>ICCV 2023</kbd>

# 2024-06
- [DETRs Beat YOLOs on Real-time Object Detection](https://arxiv.org/pdf/2304.08069) <kbd>CVPR 2024</kbd>
- [Masked-attention Mask Transformer for Universal Image Segmentation](https://arxiv.org/pdf/2112.01527) 
- [DEFORMABLE DETR: DEFORMABLE TRANSFORMERS FOR END-TO-END OBJECT DETECTION](https://arxiv.org/pdf/2010.04159) <kbd>ICLR 2021</kbd>
- [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) <kbd>Facebook AI</kbd>

# 2024-05
- [Can a Transformer Represent a Kalman Filter?](https://arxiv.org/pdf/2312.06937)
- [What the DAAM: Interpreting Stable Diffusion Using Cross Attention](https://arxiv.org/abs/2210.04885)

# 2024-04
- [SlowFast Networks for Video Recognition](https://arxiv.org/pdf/1812.03982) Facebook AI Research (FAIR)
- [Sparse R-CNN: End-to-End Object Detection with Learnable Proposals](https://arxiv.org/pdf/2011.12450)
- [DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries](https://arxiv.org/pdf/2110.06922)
- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)
- [A COMPLETE RECIPE FOR BAYESIAN KNOWLEDGE TRANSFER: OBJECT TRACKING](https://arxiv.org/abs/2210.13232) _(3D Object Tracking 2022)_
- [BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in Bird’s-Eye View](https://arxiv.org/abs/2309.02185) _(3D Object Tracking 2023)_
- [A Bayesian Detect to Track System for Robust Visual Object Tracking and Semi-Supervised Model Learning](https://arxiv.org/abs/2205.02371) _(3D Object Tracking 2022)_
- [Conjugate Priors for Bayesian Object Tracking](https://research.chalmers.se/publication/519159/file/519159_Fulltext.pdf) _(Object Tracking)_
- [An Overview of Signal Processing Techniques for Millimeter Wave MIMO Systems](https://arxiv.org/pdf/1512.03007.pdf) <kbd>IEEE Journal in Signal Processing 2016</kbd> _(MIMO wireless communication)_

# 2024-03 [Paper Writing Season]
- [Want to be Retweeted? Large Scale Analytics on Factors Impacting Retweet in Twitter Network](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5590452) _(Social Computing)_
- [Estimating Training Data Influence by Tracing Gradient Descent](https://papers.nips.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf) <kbd>NIPS 2020</kbd> _(XAI)_
- [Representer Point Selection for Explaining Deep Neural Networks](https://arxiv.org/pdf/1811.09720.pdf) <kbd>NIPS 2019</kbd> _(XAI)_
- [Sanity Checks for Saliency Maps](https://arxiv.org/pdf/1810.03292.pdf) <kbd>NIPS 2018</kbd> _(XAI)_
- [THE (UN)RELIABILITY OF SALIENCY METHODS](https://arxiv.org/pdf/1711.00867.pdf) _(XAI)_
- [A Benchmark for Interpretability Methods in Deep Neural Networks](https://arxiv.org/pdf/1806.10758.pdf) <kbd>NIPS 2019</kbd> _(XAI)_
- [SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos](https://arxiv.org/pdf/2308.09244.pdf) _(3D Object Detection)_
- [Reliable Orientation Estimation of Vehicles in High-Resolution Radar Images](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518649) _(Radar's Detection)_
- [Evaluating the visualization of what a Deep Neural Network has learned](https://arxiv.org/pdf/1509.06321.pdf) _(XAI)_

# 2024-02 [Paper Writing Season]


# 2024-01
- [Adversarial Examples: Attacks and Defenses for Deep Learning](https://arxiv.org/pdf/1712.07107.pdf) _(Adversarial Attack)_
- [An Introduction to Variable and Feature Selection](https://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf) _(Feature Learning)_
- [Layer-Wise Relevance Propagation: An Overview](https://link.springer.com/chapter/10.1007/978-3-030-28954-6_10) _(XAI)_
- [Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph](https://aclanthology.org/P18-1208/) _(Multimodal XAI)_
- [A Review on Explainability in Multimodal Deep Neural Nets](https://arxiv.org/abs/2105.07878) _(Multimodal XAI)_
- [Vision Transformer with Deformable Attention](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.pdf) <kbd>CVPR 2022</kbd> _(Vision Transformer)_
- [Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations](https://arxiv.org/abs/2202.07800) <kbd>ICLR 2022</kbd> _(Vision Transformer)_
- [Time Will Tell : new outlooks and a baseline for temporal multi-view 3d object detection](https://arxiv.org/pdf/2210.02443.pdf) _(3D Object Detection)_

# 2023-12
- [Exploring Recurrent Long-term Temporal Fusion for Multi-view 3D Perception](https://arxiv.org/abs/2303.05970) _(3D Object Detection)_
- [Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection](https://arxiv.org/abs/2310.15670) <kbd>NIPS 2023</kbd> _(3D Object Detection)_
- [UniM2AE: Multi-modal Masked Autoencoders with Unified 3D Representation for 3D Perception in Autonomous Driving](https://arxiv.org/abs/2308.10421) _(3D Object Detection)_
- [SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos](https://arxiv.org/abs/2308.09244) <kbd>ICCV 2023</kbd> _(3D Object Detection)_
- [Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection](https://arxiv.org/abs/2303.11926) _(3D Object Detection)_
- [Temporal Enhanced Training of Multi-view 3D Object Detector via Historical Object Prediction](https://arxiv.org/abs/2304.00967) _(3D Object Detection)_
- [Textual Explanations for Self-Driving Vehicles](https://arxiv.org/pdf/1807.11546.pdf) <kbd>ECCV 2018</kdb> _(MXAI)_
- [Visual Relationship Detection with Language Priors](https://arxiv.org/pdf/1608.00187.pdf) <kbd>ECCV 2016</kbd> _(MXAI)_
- [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874) <kbd>NIPS 2017</kbd> _(XAI)_
- [Learning Important Features Through Propagating Activation Differences](https://arxiv.org/pdf/1704.02685.pdf) _(XAI)_
- [Consistent Individualized Feature Attribution for Tree Ensembles](https://arxiv.org/pdf/1802.03888.pdf) _(XAI)_
- [RISE: Randomized Input Sampling for Explanation of Black-box Models](https://arxiv.org/pdf/1806.07421.pdf) <kbd>BMVC 2018</kbd> _(XAI)_
- [Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions](https://arxiv.org/pdf/2306.05731.pdf) _(Multimodal Learning)_
- [Understanding Individual Decisions of CNNs via Contrastive Backpropagation](https://arxiv.org/abs/1812.02100) <kbd>ACCV 2018</kbd> _(XAI)_
- [Reliable Post hoc Explanations:Modeling Uncertainty in Explainability](https://proceedings.neurips.cc/paper/2021/file/4e246a381baf2ce038b3b0f82c7d6fb4-Paper.pdf) <kbd>NIPS 2021</kbd> _(XAI)
- [Transformer Interpretability Beyond Attention Visualization](https://openaccess.thecvf.com/content/CVPR2021/papers/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.pdf) <kbd>CVPR 2021</kbd> _(XAI)
- [On Embeddings for Numerical Features in Tabular Deep Learning](https://arxiv.org/abs/2203.05556v1) _(Tabular Models)_
- [Revisiting Deep Learning Models for Tabular Data](https://arxiv.org/pdf/2106.11959.pdf) <kbd>NIPS 2021</kbd> _(Tabular Models)_
- [TabTransformer: Tabular Data Modeling Using Contextual Embeddings](https://arxiv.org/abs/2012.06678) _(Tabular Models)_
- [Deep Neural Networks and Tabular Data: A Survey](https://arxiv.org/pdf/2110.01889.pdf) <kbd>IEEE 2021</kbd> _(Tabular Models)_
- [Towards Interpretable Semantic Segmentation via Gradient-weighted Class Activation Mapping](https://arxiv.org/abs/2002.11434) <kbd>AAAI 2020</kbd> _(XAI)_
- [Explaining NonLinear Classification Decisions with Deep Taylor Decomposition](https://arxiv.org/abs/1512.02479) _(XAI)_
- [Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks](https://www.researchgate.net/publication/343270559_Score-CAM_Score-Weighted_Visual_Explanations_for_Convolutional_Neural_Networks) <kbd>CVPR 2020</kbd> _(XAI)_
- [On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0130140&type=printable) _(XAI)_
- [Grad-CAM: Why did you say that?](https://arxiv.org/abs/1611.07450) <kbd>NIPS 2016</kbd> _(XAI)_
- [Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806) <kbd>ICLR 2015</kbd> _(XAI)_
- [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901) _(XAI)_
- [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825) <kbd>CVPR 2017</kbd> _(XAI)_
- [Parameter-free Online Test-time Adaptation](https://arxiv.org/pdf/2201.05718.pdf) <kbd>CVPR 2022</kbd> _(Domain Adaptation)_
- [TOWARDS STABLE TEST-TIME ADAPTATION IN DYNAMIC WILD WORLD](https://arxiv.org/pdf/2302.12400.pdf) <kbd>ICLR 2023</kbd> _(Domain Adaptation)_
- [Robust Test-Time Adaptation in Dynamic Scenarios](https://arxiv.org/pdf/2303.13899.pdf) <kbd>CVPR 2023</kbd> _(Domain Adaptation)_
- [BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers](https://arxiv.org/abs/2203.17270) <kbd>ECCV 2022</kbd> _(3D Object Detection)_


# 2023-11
- [Learning to Prompt for Vision-Language Models](https://arxiv.org/pdf/2109.01134.pdf) <kbd>IJCV 2022</kbd> _(Multi-Modal Learning)_
- [Grounding Language Models to Images for Multimodal Inputs and Outputs](https://arxiv.org/pdf/2301.13823.pdf) <kbd>ICML 2023</kbd> _(Multi-Modal Learning)_
- [InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/pdf/2305.06500.pdf) _(Multi-Modal Learning)_
- [Deep Kalman Filters](https://arxiv.org/abs/1511.05121) _(Kalman Filters)_
- [Simple-BEV: What Really Matters for Multi-Sensor BEV Perception?](https://arxiv.org/abs/2206.07959) <kbd>ICRA 2023</kbd> _(3D Object Detection)_
- [BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection](https://arxiv.org/abs/2203.17054)
- [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593) <kbd>CVPR 2017 </kbd> _(Point Cloud Models)_
- [PointMixer: MLP-Mixer for Point Cloud Understanding](https://arxiv.org/pdf/2111.11187.pdf) <kbd>ECCV 2022 </kbd>
- [Radar Sensor-Based Estimation of Vehicle Orientation for Autonomous Driving](https://ieeexplore.ieee.org/document/9913885) <kbd>IEEE Sensors 2022 </kbd>
- [Ego-motion Estimation for SAR Image Generation in Automotive Radar Systems]
- [BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo](https://arxiv.org/abs/2209.10248) <kbd>AAAI 2023 </kbd>
- [MatrixVT: Efficient Multi-Camera to BEV Transformation for 3D Perception](https://arxiv.org/abs/2211.10593) <kbd>ICCV 2023</kbd>
- [Autoregressive Visual Tracking](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.html) <kbd>CVPR 2023</kbd> _(Visual Tracking, *)_
- [Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention](https://proceedings.mlr.press/v119/katharopoulos20a.html) <kbd>ICML 2020</kbd> _(Deep Learning Model, ***)_
- [Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D](https://arxiv.org/abs/2008.05711) <kbd>ECCV 2020</kbd>
- [BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection](https://arxiv.org/abs/2206.10092) <kbd>AAAI 2023</kbd> _(3D Object Detection)_
- [HVDetFusion : A Simple and Robust Camera-Radar Fusion Framework](https://arxiv.org/abs/2307.11323) _(3D Sensor Fusion, ****)_
- [TabNet: Attentive Interpretable Tabular Learning](https://ojs.aaai.org/index.php/AAAI/article/view/16826) <kbd>AAAI 2021</kbd> _(Tabular Models)_
- [Why do tree-based models still outperform deep learning on typical tabular data?](https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Supplemental-Datasets_and_Benchmarks.pdf) <kbd>NIPS 2022</kbd> _(Tabular Models, **)_
- [ON THE DUALITY BETWEEN CONTRASTIVE AND NONCONTRASTIVE SELF-SUPERVISED LEARNING](https://openreview.net/forum?id=kDEL91Dufpa) <kbd>ICLR 2023</kbd> _(Contrastive Learning, *)_
- [Corrupted Image Modeling for Self-Supervised Visual Pre-Training](https://openreview.net/forum?id=09hVcSDkea) <kbd>ICLR 2023</kbd> _(Self-Supervised Learning, **)_
- [Point Transformer](https://arxiv.org/abs/2012.09164) _(Deep Learning Architecture)_
- [A Deep Learning-based Radar and Camera Sensor Fusion Architecture for Object Detection](https://arxiv.org/abs/2005.07431) (_2D Sensor Fusion_)
- [RVNet: Deep Sensor Fusion of Monocular Camera and Radar for Image-based Obstacle Detection in Challenging Environments](https://www.researchgate.net/publication/335833918_RVNet_Deep_Sensor_Fusion_of_Monocular_Camera_and_Radar_for_Image-based_Obstacle_Detection_in_Challenging_Environments?enrichId=rgreq-3c3ca58bdea789dc98b91a8b24745164-XXX&enrichSource=Y292ZXJQYWdlOzMzNTgzMzkxODtBUzo4MDM2MjIxODcxNzU5NDBAMTU2ODYwOTg2ODkzMw%3D%3D&el=1_x_3&_esc=publicationCoverPdf) (_2D Sensor Fusion_)
- [Radar + RGB Fusion For Robust Object Detection In Autonomous Vehicle](https://ieeexplore.ieee.org/abstract/document/9191046) (_2D Sensor Fusion_)
- [YOdar: Uncertainty-based Sensor Fusion for Vehicle Detection with Camera and Radar Sensors](https://arxiv.org/abs/2010.03320) (_2D Sensor Fusion_)
- [CenterFusion: Center-based Radar and Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2011.04841) (_3D Sensor Fusion_)
- [RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition](https://arxiv.org/abs/2011.08981) <kbd>IEEE Sensors</kbd> (_2D Sensor Fusion_)
- [Radar+RGB Attentive Fusion for Robust Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2008.13642) (_2D Sensor Fusion_)
- [RODNet: A Real-Time Radar Object Detection Network Cross-Supervised by Camera-Radar Fused Object 3D Localization](https://arxiv.org/abs/2102.05150) (_2D Sensor Fusion_)
- [3D Object Detection of Cars and Pedestrians by Deep Neural Networks from Unit-Sharing One-Shot NAS]() (_3D Sensor Fusion_)
- [Radar Camera Fusion via Representation Learning in Autonomous Driving](https://arxiv.org/pdf/2103.07825.pdf) (_3D Sensor Fusion_)
- [Robust Small Object Detection on the Water Surface through Fusion of Camera and Millimeter Wave Radar](https://openaccess.thecvf.com/content/ICCV2021/papers/Cheng_Robust_Small_Object_Detection_on_the_Water_Surface_Through_Fusion_ICCV_2021_paper.pdf) <kbd>ICCV 2021</kbd> (_2D Sensor Fusion_)
- [GRIF Net: Gated Region of Interest Fusion Network for Robust 3D Object Detection from Radar Point Cloud and Monocular Image](https://ieeexplore.ieee.org/document/9341177) (_2D Sensor Fusion_)
- [FUTR3D: A Unified Sensor Fusion Framework for 3D Detection](https://arxiv.org/abs/2203.10642) <kbd>CVPR 2023</kbd> (_3D Sensor Fusion_)
- [Simple-BEV: What Really Matters for Multi-Sensor BEV Perception?](https://arxiv.org/abs/2206.07959) (_3D Sensor Fusion_)
- [Bridging the View Disparity Between Radar and Camera Features for Multi-modal Fusion 3D Object Detection](https://arxiv.org/pdf/2208.12079.pdf) (_3D Sensor Fusion_)
- [RadSegNet: A Reliable Approach to Radar Camera Fusion](https://arxiv.org/abs/2208.03849) (_3D Sensor Fusion_)
- [CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer](https://arxiv.org/abs/2209.06535) (_3D Sensor Fusion_)
- [CramNet: Camera-Radar Fusion with Ray-Constrained Cross-Attention for Robust 3D Object Detection](https://arxiv.org/abs/2210.09267) (_3D Sensor Fusion_)
<br>

# 2023-10
- [A Theoretical Study on Solving Continual Learning](https://papers.nips.cc/paper_files/paper/2022/hash/20f44da80080d76bbc35bca0027f14e6-Abstract-Conference.html) <kbd>NIPS 2022</kbd> _(Continual Learning, ****)_
- [Spatial Attention Fusion for Obstacle Detection Using MmWave Radar and Vision Sensor](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070402/pdf/sensors-20-00956.pdf) _(Sensor Fusion, *****)_
- [Multi-sensor data fusion using Bayesian programming: An automotive application](https://ieeexplore.ieee.org/document/1187989) _(Sensor Fusion, ****)_
- [Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review](https://arxiv.org/abs/2304.10410) _(Sensor Fusion, ****)_
- [CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception](https://arxiv.org/abs/2304.00670) <kbd>ICCV 2023</kbd> _(Sensor Fusion, ****)_
<br>

# 2023-09
- [On Layer Normalization in the Transformer Architecture](https://arxiv.org/pdf/2002.04745.pdf) <kbd>ICML 2020</kbd> _(Normalization, ***)_
- [REMIXMATCH: SEMI-SUPERVISED LEARNING WITH DISTRIBUTION ALIGNMENT AND AUGMENTATION ANCHORING](https://openreview.net/pdf?id=HklkeR4KPB) <kbd>ICLR 2020</kbd> _(Augmentation, *)_
- [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913) <kbd>NIPS 2018</kbd> _(Deep Learning Theory, *****)_
- [Sharpness-Aware Minimization for Efficiently Improving Generalization](https://arxiv.org/abs/2010.01412) <kbd>ICLR 2021</kbd> _(Optimization, ****)_
- [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412) <kbd>ICLR 2018</kbd> _(Data Augmentation, ***)_
- [AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights](https://arxiv.org/abs/2006.08217) <kbd>ICLR 2021</kbd> _(Optimization, ***)_
<br>

# 2022 and Before
- [Spectral Normalization for Generative Adversarial Networks](https://arxiv.org/abs/1802.05957) <kbd>ICLR 2018</kbd> _(Generative Adversarial Network)_
- [cGANs with Projection Discriminator](https://arxiv.org/abs/1802.05637) <kdb>ICLR 2018</kbd> _(Generative Adversarial Network)_
- [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391) <kbd>IJCV 2019</kbd> _(XAI)_
- [Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One](https://arxiv.org/abs/1912.03263) <kbd>ICLR 2019</kbd> _(Energy Based Model)_
- [Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling](https://arxiv.org/abs/2003.06060) <kbd>NeurIPS 2020</kbd> _(Energy Based Model)_
- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) <kbd>NeurIPS 2014</kbd> _(Generative Adversarial Network)_
- [Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition](https://arxiv.org/abs/2003.14111) <kbd>CVPR 2020</kbd> _(Human Action Classification)_
- [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) <kbd>CVPR 2015</kbd> _(2D Object Detection)_
<br>


# Papers to Read

### Object Detection
- [Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud](https://arxiv.org/pdf/2003.01251.pdf) <kbd>CVPR 2020</kbd>
- [Vision Transformer with Deformable Attention](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.pdf) <kbd>CVPR 2022</kbd>
- [FCOS: Fully Convolutional One-Stage Object Detection](https://arxiv.org/abs/1904.01355) <kbd>ICCV 2019</kbd>
- [Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection](https://arxiv.org/abs/2210.02443) <kbd>ICLR 2023</kbd>
- [Simple-BEV: What Really Matters for Multi-Sensor BEV Perception?](https://arxiv.org/abs/2206.07959)

### Continual Learning
- [Self-Supervised Models are Continual Learners](https://arxiv.org/abs/2112.04215) <kbd>CVPR 2022</kbd>
- [Theory on Forgetting and Generalization of Continual Learning](https://proceedings.mlr.press/v202/lin23f.html) <kbd>ICML 2023</kbd>
- [Continual evaluation for lifelong learning: Identifying the stability gap](https://openreview.net/forum?id=Zy350cRstc6)  <kbd>ICLR 2023</kbd>
- [An Efficient Domain-Incremental Learning Approach to Drive in All Weather Conditions](https://openaccess.thecvf.com/content/CVPR2022W/V4AS/papers/Mirza_An_Efficient_Domain-Incremental_Learning_Approach_To_Drive_in_All_Weather_CVPRW_2022_paper.pdf) <kbd>CVPR 2022</kbd>

### Sensor Fusion


### Generative Model
- [Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model](https://arxiv.org/abs/2208.07791) <kbd>2022</kbd>
<br>
