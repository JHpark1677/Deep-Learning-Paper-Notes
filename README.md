# About
My name is Park Jae Hyun. I major in Electronic and Electrical Engineering at [POSTECH](https://www.postech.ac.kr/). I'm a graduate student at Radio Technology Lab of [Seoul National University](https://www.snu.ac.kr/index.html). 
Now, I'm working on 3D Object Detection Tasks exploiting the radar-camera sensor fusion techniques. And I'm highly motivated to create technologically fancy outputs.

This repository is the collection of various research papers that I'm dealing with, which is inspired by [Denny britz](https://github.com/dennybritz/deeplearning-papernotes), [Daniel Takeshi](https://github.com/DanielTakeshi/Paper_Notes) and [Patric Langechuan Liu](https://patrick-llgc.github.io/Learning-Deep-Learning/). The number of asteroid indicates a degree of achievement of the papaer understanding.
For example, the understanding score is based on the checklists
| Main Ideas | Contribution | Methodology | Training Details | Experiments |
| :-----: | :----------: | :----------: | :----------: | :----------: |
<br>

# 2023-11
- [
- [Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention](https://proceedings.mlr.press/v119/katharopoulos20a.html) <kbd>ICML 2020</kbd>
- [Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D](https://arxiv.org/abs/2008.05711) <kbd>ECCV 2020</kbd>
- [BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection](https://arxiv.org/abs/2206.10092) <kbd>AAAI 2023</kbd> _(3D Object Detection)_
- [HVDetFusion : A Simple and Robust Camera-Radar Fusion Framework](https://arxiv.org/abs/2307.11323) _(3D Sensor Fusion, ****)_
- [TabNet: Attentive Interpretable Tabular Learning](https://ojs.aaai.org/index.php/AAAI/article/view/16826) <kbd>AAAI 2021</kbd> _(Tabular Models)_
- [Why do tree-based models still outperform deep learning on typical tabular data?](https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Supplemental-Datasets_and_Benchmarks.pdf) <kbd>NIPS 2022</kbd> _(Tabular Models, **)_
- [ON THE DUALITY BETWEEN CONTRASTIVE AND NONCONTRASTIVE SELF-SUPERVISED LEARNING](https://openreview.net/forum?id=kDEL91Dufpa) <kbd>ICLR 2023</kbd> _(Contrastive Learning, *)_
- [Corrupted Image Modeling for Self-Supervised Visual Pre-Training](https://openreview.net/forum?id=09hVcSDkea) <kbd>ICLR 2023</kbd> _(Self-Supervised Learning, **)_
- [Point Transformer](https://arxiv.org/abs/2012.09164) _(Deep Learning Architecture)_
- [A Deep Learning-based Radar and Camera Sensor Fusion Architecture for Object Detection](https://arxiv.org/abs/2005.07431) (_2D Sensor Fusion_)
- [RVNet: Deep Sensor Fusion of Monocular Camera and Radar for Image-based Obstacle Detection in Challenging Environments](https://www.researchgate.net/publication/335833918_RVNet_Deep_Sensor_Fusion_of_Monocular_Camera_and_Radar_for_Image-based_Obstacle_Detection_in_Challenging_Environments?enrichId=rgreq-3c3ca58bdea789dc98b91a8b24745164-XXX&enrichSource=Y292ZXJQYWdlOzMzNTgzMzkxODtBUzo4MDM2MjIxODcxNzU5NDBAMTU2ODYwOTg2ODkzMw%3D%3D&el=1_x_3&_esc=publicationCoverPdf) (_2D Sensor Fusion_)
- [Radar + RGB Fusion For Robust Object Detection In Autonomous Vehicle](https://ieeexplore.ieee.org/abstract/document/9191046) (_2D Sensor Fusion_)
- [YOdar: Uncertainty-based Sensor Fusion for Vehicle Detection with Camera and Radar Sensors](https://arxiv.org/abs/2010.03320) (_2D Sensor Fusion_)
- [CenterFusion: Center-based Radar and Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2011.04841) (_3D Sensor Fusion_)
- [RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition](https://arxiv.org/abs/2011.08981) <kbd>IEEE Sensors</kbd> (_2D Sensor Fusion_)
- [Radar+RGB Attentive Fusion for Robust Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2008.13642) (_2D Sensor Fusion_)
- [RODNet: A Real-Time Radar Object Detection Network Cross-Supervised by Camera-Radar Fused Object 3D Localization](https://arxiv.org/abs/2102.05150) (_2D Sensor Fusion_)
- [3D Object Detection of Cars and Pedestrians by Deep Neural Networks from Unit-Sharing One-Shot NAS]() (_3D Sensor Fusion_)
- [Radar Camera Fusion via Representation Learning in Autonomous Driving](https://arxiv.org/pdf/2103.07825.pdf) (_3D Sensor Fusion_)
- [Robust Small Object Detection on the Water Surface through Fusion of Camera and Millimeter Wave Radar](https://openaccess.thecvf.com/content/ICCV2021/papers/Cheng_Robust_Small_Object_Detection_on_the_Water_Surface_Through_Fusion_ICCV_2021_paper.pdf) <kbd>ICCV 2021</kbd> (_2D Sensor Fusion_)
- [GRIF Net: Gated Region of Interest Fusion Network for Robust 3D Object Detection from Radar Point Cloud and Monocular Image](https://ieeexplore.ieee.org/document/9341177) (_2D Sensor Fusion_)
- [FUTR3D: A Unified Sensor Fusion Framework for 3D Detection](https://arxiv.org/abs/2203.10642) <kbd>CVPR 2023</kbd> (_3D Sensor Fusion_)
- [Simple-BEV: What Really Matters for Multi-Sensor BEV Perception?](https://arxiv.org/abs/2206.07959) (_3D Sensor Fusion_)
- [Bridging the View Disparity Between Radar and Camera Features for Multi-modal Fusion 3D Object Detection](https://arxiv.org/pdf/2208.12079.pdf) (_3D Sensor Fusion_)
- [RadSegNet: A Reliable Approach to Radar Camera Fusion](https://arxiv.org/abs/2208.03849) (_3D Sensor Fusion_)
- [CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer](https://arxiv.org/abs/2209.06535) (_3D Sensor Fusion_)
- [CramNet: Camera-Radar Fusion with Ray-Constrained Cross-Attention for Robust 3D Object Detection](https://arxiv.org/abs/2210.09267) (_3D Sensor Fusion_)
<br>

# 2023-10
- [A Theoretical Study on Solving Continual Learning](https://papers.nips.cc/paper_files/paper/2022/hash/20f44da80080d76bbc35bca0027f14e6-Abstract-Conference.html) <kbd>NIPS 2022</kbd> _(Continual Learning, ****)_
- [Spatial Attention Fusion for Obstacle Detection Using MmWave Radar and Vision Sensor](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070402/pdf/sensors-20-00956.pdf) _(Sensor Fusion, *****)_
- [Multi-sensor data fusion using Bayesian programming: An automotive application](https://ieeexplore.ieee.org/document/1187989) _(Sensor Fusion, ****)_
- [Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review](https://arxiv.org/abs/2304.10410) _(Sensor Fusion, ****)_
- [CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception](https://arxiv.org/abs/2304.00670) <kbd>ICCV 2023</kbd> _(Sensor Fusion, ****)_
<br>

# 2023-09
- [On Layer Normalization in the Transformer Architecture](https://arxiv.org/pdf/2002.04745.pdf) <kbd>ICML 2020</kbd> _(Normalization, ***)_
- [REMIXMATCH: SEMI-SUPERVISED LEARNING WITH DISTRIBUTION ALIGNMENT AND AUGMENTATION ANCHORING](https://openreview.net/pdf?id=HklkeR4KPB) <kbd>ICLR 2020</kbd> _(Augmentation, *)_
- [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913) <kbd>NIPS 2018</kbd> _(Deep Learning Theory, *****)_
- [Sharpness-Aware Minimization for Efficiently Improving Generalization](https://arxiv.org/abs/2010.01412) <kbd>ICLR 2021</kbd> _(Optimization, ****)_
- [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412) <kbd>ICLR 2018</kbd> _(Data Augmentation, ***)_
- [AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights](https://arxiv.org/abs/2006.08217) <kbd>ICLR 2021</kbd> _(Optimization, ***)_
<br>

# 2022 and Before
- [Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One](https://arxiv.org/abs/1912.03263) <kbd>ICLR 2019</kbd> _(Energy Based Model)_
- [Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling](https://arxiv.org/abs/2003.06060) <kbd>NeurIPS 2020</kbd> _(Energy Based Model)_
- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) <kbd>NeurIPS 2014</kbd> _(Generative Adversarial Network)_
- [Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition](https://arxiv.org/abs/2003.14111) <kbd>CVPR 2020</kbd> _(Human Action Classification)_
- [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) <kbd>CVPR 2015</kbd> _(2D Object Detection)_
<br>


# Papers to Read

### Object Detection
- [Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud](https://arxiv.org/pdf/2003.01251.pdf) <kbd>CVPR 2020</kbd>
- [Vision Transformer with Deformable Attention](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.pdf) <kbd>CVPR 2022</kbd>
- [FCOS: Fully Convolutional One-Stage Object Detection](https://arxiv.org/abs/1904.01355) <kbd>ICCV 2019</kbd>
- [Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection](https://arxiv.org/abs/2210.02443) <kbd>ICLR 2023</kbd>
- [Simple-BEV: What Really Matters for Multi-Sensor BEV Perception?](https://arxiv.org/abs/2206.07959)

### Continual Learning
- [Self-Supervised Models are Continual Learners](https://arxiv.org/abs/2112.04215) <kbd>CVPR 2022</kbd>
- [Theory on Forgetting and Generalization of Continual Learning](https://proceedings.mlr.press/v202/lin23f.html) <kbd>ICML 2023</kbd>
- [Continual evaluation for lifelong learning: Identifying the stability gap](https://openreview.net/forum?id=Zy350cRstc6)  <kbd>ICLR 2023</kbd>
- [An Efficient Domain-Incremental Learning Approach to Drive in All Weather Conditions](https://openaccess.thecvf.com/content/CVPR2022W/V4AS/papers/Mirza_An_Efficient_Domain-Incremental_Learning_Approach_To_Drive_in_All_Weather_CVPRW_2022_paper.pdf) <kbd>CVPR 2022</kbd>

### Sensor Fusion
- 

### Generative Model
- [Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model](https://arxiv.org/abs/2208.07791) <kbd>2022</kbd>
<br>
